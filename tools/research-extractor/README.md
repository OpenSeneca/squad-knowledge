# research-extractor ‚Äî Extract Content from Research

Extract tweet drafts, blog angles, and signup links from agent research outputs.

## What It Does

Scans Marcus/Galen outputs and learnings for content metadata:

- **Tweet Drafts** (`## Tweet Draft`) ‚Äî Ready-to-post tweets
- **Blog Angles** (`BLOG ANGLE:`) ‚Äî Blog post ideas
- **Signup Links** (`SIGNUP:`) ‚Äî Newsletter signup links

**Output:** Single markdown file Seneca can scan for content to post.

## Why This Matters

Seneca needs to post regularly, but manually finding content across agents' outputs is tedious.

This tool:
- Scans all agent outputs automatically
- Extracts specific content markers
- Produces one consolidated file
- Saves Seneca scanning time

## Installation

```bash
ln -s /path/to/research-extractor.py ~/.local/bin/research-extractor
chmod +x research-extractor.py
```

Already symlinked in this workspace: `~/.local/bin/research-extractor`

## Usage

### Scan All Outputs (Default: Last 7 Days)

```bash
research-extractor
```

### Scan Last 3 Days

```bash
research-extractor --days 3
```

### Save to Specific File

```bash
research-extractor --output content-extract.md
```

### Scan Learnings from Specific Agents

```bash
research-extractor --agents marcus galen --scan learnings
```

### Combine Outputs and Learnings

```bash
research-extractor --scan both
```

## Examples

### Basic Scan

```bash
$ research-extractor

üìÇ Scanning outputs...
üîç Scanning 21 recent files...

üìä Generating content extract...

‚úÖ Extracted:
   - 0 tweet draft(s)
   - 11 blog angle(s)
   - 0 signup link(s)
   - Total: 11 items

üíæ Saving to file...
‚úÖ Saved: /home/exedev/.openclaw/workspace/outputs/content-extract-20260217-2055.md

üìÑ Preview (first 500 chars):
------------------------------------------------------------
# Research Content Extract

**Generated:** 2026-02-17 20:55 UTC
**Scan Period:** Last 7 days

---

## Tweet Drafts (0)

No tweet drafts found.

---

## Blog Angles (11)

### Angle 1
**Source:** 2026-02-10-edge-ai-tinyml-deployment.md
**Date:** 2026-02-10

Justin can create an "Edge AI Deployment Guide" covering TinyML optimization techniques...
```

### Scan Specific Agents

```bash
$ research-extractor --agents marcus galen --days 3

üìÇ Scanning learnings...
üîç Scanning 8 learning files...

üìä Generating content extract...

‚úÖ Extracted:
   - 2 tweet draft(s)
   - 5 blog angle(s)
   - 1 signup link(s)
   - Total: 8 items
```

### Custom Output Path

```bash
$ research-extractor --output ~/workspace/outputs/daily-content.md

üíæ Saving to file...
‚úÖ Saved: /home/exedev/.openclaw/workspace/outputs/daily-content.md
```

## Output Format

The extract is a single markdown file with three sections:

```markdown
# Research Content Extract

**Generated:** 2026-02-17 20:55 UTC
**Scan Period:** Last 7 days

---

## Tweet Drafts (0)

No tweet drafts found.

---

## Blog Angles (11)

### Angle 1
**Source:** 2026-02-10-edge-ai-tinyml-deployment.md
**Date:** 2026-02-10

Justin can create an "Edge AI Deployment Guide" covering TinyML optimization techniques...

---

## Signup Links (0)

No signup links found.

---

## Summary

- **Tweet Drafts:** 0
- **Blog Angles:** 11
- **Signup Links:** 0
- **Total:** 11 items

---

*Generated by research-extractor for Seneca*
```

## What Gets Extracted

### Tweet Drafts

**Marker:** `## Tweet Draft` (case-insensitive)

```markdown
## Tweet Draft

Just shipped a new research tool that extracts content from agent outputs. Now Seneca can find blog angles and tweet drafts in seconds instead of minutes. #OpenSeneca
```

**Output:**

```markdown
### Draft 1
**Source:** research-notes.md
**Date:** 2026-02-17

Just shipped a new research tool that extracts content from agent outputs. Now Seneca can find blog angles and tweet drafts in seconds instead of minutes. #OpenSeneca
```

### Blog Angles

**Marker:** `BLOG ANGLE:` (case-insensitive)

```markdown
BLOG ANGLE: Justin can create an "Edge AI Deployment Guide" covering TinyML optimization techniques, quantization trade-offs, and performance patterns.
```

**Output:**

```markdown
### Angle 1
**Source:** edge-ai-research.md
**Date:** 2026-02-17

Justin can create an "Edge AI Deployment Guide" covering TinyML optimization techniques, quantization trade-offs, and performance patterns.
```

### Signup Links

**Marker:** `SIGNUP:` (case-insensitive)

```markdown
SIGNUP: https://rundatadrun.substack.com/subscribe
```

**Output:**

```markdown
### Link 1
**Source:** newsletter-info.md
**Date:** 2026-02-17

https://rundatadrun.substack.com/subscribe
```

## Features

- ‚úÖ **Scans outputs** ‚Äî Agent outputs in `~/workspace/outputs/`
- ‚úÖ **Scans learnings** ‚Äî Agent learnings in `~/learnings/`
- ‚úÖ **Flexible time window** ‚Äî Scan last N days (default: 7)
- ‚úÖ **Agent filtering** ‚Äî Scan specific agents (marcus, galen, etc.)
- ‚úÖ **Deduplication** ‚Äî Removes duplicate entries
- ‚úÖ **Metadata included** ‚Äî Source file and date for each item
- ‚úÖ **Consolidated output** ‚Äî Single markdown file
- ‚úÖ **Zero dependencies** ‚Äî Pure Python

## Use Cases

### For Seneca (Content Posting)

```bash
# Daily content scan
research-extractor --days 1

# Scan for tweet drafts to post
research-extractor --scan outputs --days 3

# Find blog angles for newsletter
research-extractor --scan learnings --agents marcus galen
```

### For Justin (Research Review)

```bash
# Weekly content review
research-extractor --days 7 --output weekly-content.md

# Scan specific research topics
research-extractor --agents marcus --days 14

# Combine all sources
research-extractor --scan both --output full-extract.md
```

### For Marcus/Galen (Content Metadata)

```bash
# See what content markers you have
research-extractor --scan learnings --days 7

# Find your blog angles
research-extractor --scan outputs --days 30
```

## Integration with Other Tools

### Squad Output Digest

```bash
# Get daily squad activity
squad-output-digest

# Extract content from that digest
research-extractor --days 1
```

### Twitter-Post Script

```bash
# Extract tweet drafts
research-extractor --days 3

# Seneca reads the extract and posts
# (using twitter-post script)
```

### Blog Assistant

```bash
# Extract blog angles
research-extractor --days 7 --output angles.md

# Use blog-assistant with those angles
blog-assistant --topic "AI Research" --notes angles.md
```

## Workflow

### For Daily Content Posting

1. **Marcus/Galen** research and output content
2. They **mark content** with `## Tweet Draft`, `BLOG ANGLE:`, `SIGNUP:`
3. **research-extractor** scans outputs daily
4. **Seneca** reads the extract and posts content

### For Weekly Review

1. Run `research-extractor --days 7`
2. Review tweet drafts, blog angles, signup links
3. Decide what to post this week
4. Seneca posts selected content

## Best Practices

### For Marcus/Galen

**Mark content clearly:**

```markdown
## Tweet Draft

AI models are getting smaller and faster. TinyML is enabling edge deployment on $5 microcontrollers. #EdgeAI #TinyML

BLOG ANGLE: "The TinyML Revolution" - How AI models are shrinking to run on microcontrollers and why it matters for IoT devices.

SIGNUP: https://rundatadrun.substack.com/subscribe
```

### For Seneca

**Run daily:**

```bash
# Add to crontab
0 9 * * * research-extractor --days 1

# Check the extract file
cat ~/workspace/outputs/content-extract-*.md | head -100
```

### For Justin

**Review weekly:**

```bash
# Get weekly extract
research-extractor --days 7 --output weekly-content.md

# Edit and prioritize
vim weekly-content.md
```

## Troubleshooting

### No Content Found

```bash
# Check if outputs exist
ls -la ~/.openclaw/workspace/outputs/

# Check recent files
find ~/.openclaw/workspace/outputs/ -mtime -7

# Ensure content markers are present
grep -i "tweet draft\|blog angle\|signup:" ~/.openclaw/workspace/outputs/*.md
```

### Wrong Date Range

```bash
# Check file modification times
stat ~/.openclaw/workspace/outputs/*.md

# Increase days parameter
research-extractor --days 30
```

### Duplicate Entries

The tool automatically deduplicates based on source file + content. If you see duplicates, check:
- Are you scanning both outputs and learnings with `--scan both`?
- Are there duplicate files in different directories?

## Future Enhancements

- [ ] Auto-post tweet drafts via twitter-post script
- [ ] Export to JSON for programmatic use
- [ ] Filter by content type (tweets only, angles only)
- [ ] Add more markers (e.g., `THREAD:`, `LINKEDIN:`)
- [ ] Schedule daily runs via cron/systemd
- [ ] Integration with squad-dashboard for monitoring

## Limitations

- **Text-based only** ‚Äî Doesn't scan images or PDFs
- **Markdown only** ‚Äî Works best with .md files
- **Static markers** ‚Äî Requires exact marker formats
- **No auto-posting** ‚Äî Extracts content, doesn't post

## License

MIT License

## Author

OpenSeneca Squad Toolset

---

**Content extraction in seconds.**

For Seneca, Marcus, Galen ‚Äî and anyone managing research outputs.
